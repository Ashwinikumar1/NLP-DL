{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective : This code make use of complaint data against financial companies to perform following tasks on the data\n",
    "    1. Create Topic models to classify comlplaints in various categories.\n",
    "    2. We will do test preprcessingw here which remove all token which belong to org and other preprocessing\n",
    "    3. We will try out two Topic Modelling Algorithms\n",
    "        1. Latent Dirichtlet ALogorithm - In my exp does not work well on short text data\n",
    "        2. Non Negative Matrix factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the Dataset\n",
    "The dataset comprises of Consumer Complaints on Financial products and weâ€™ll see how to classify consumer complaints text into these categories: Debt collection, Consumer Loan, Mortgage, Credit card, Credit reporting, Student loan, Bank account or service, Payday loan, Money transfers, Other financial service, Prepaid card.\n",
    "Also we will try to identify the companies from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the complaints data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "complaint_data = pd.read_csv(\"Consumer_Complaints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_received', 'product', 'sub_product', 'issue', 'sub_issue',\n",
       "       'consumer_complaint_narrative', 'company_public_response', 'company',\n",
       "       'state', 'zip_code', 'tags', 'consumer_consent_provided?',\n",
       "       'submitted_via', 'date_sent_to_company', 'company_response_to_consumer',\n",
       "       'timely_response?', 'consumer_disputed?', 'complaint_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert the columns names so that they don't have space and are more readable\n",
    "complaint_data.columns = [i.lower().replace(\" \",\"_\").replace(\"-\",\"_\") for i in complaint_data.columns]\n",
    "complaint_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets understand the shape an dtypes of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is  (670598, 18)\n",
      "The data types for our data are as follows \n"
     ]
    }
   ],
   "source": [
    "print (\"The shape of data is \",complaint_data.shape)\n",
    "print (\"The data types for our data are as follows \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The number of unique values in each column is as follows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date_received</td>\n",
       "      <td>670598</td>\n",
       "      <td>1818</td>\n",
       "      <td>08/27/2015</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "      <td>670598</td>\n",
       "      <td>12</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>210324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub_product</td>\n",
       "      <td>472396</td>\n",
       "      <td>47</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>81715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue</td>\n",
       "      <td>670598</td>\n",
       "      <td>95</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>106455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub_issue</td>\n",
       "      <td>269868</td>\n",
       "      <td>68</td>\n",
       "      <td>Account status</td>\n",
       "      <td>32633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>consumer_complaint_narrative</td>\n",
       "      <td>114704</td>\n",
       "      <td>112690</td>\n",
       "      <td>I am filing this complaint because Experian ha...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>company_public_response</td>\n",
       "      <td>145197</td>\n",
       "      <td>10</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>57364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company</td>\n",
       "      <td>670598</td>\n",
       "      <td>3933</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>61720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>state</td>\n",
       "      <td>665293</td>\n",
       "      <td>62</td>\n",
       "      <td>CA</td>\n",
       "      <td>97640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zip_code</td>\n",
       "      <td>665274</td>\n",
       "      <td>27889</td>\n",
       "      <td>300XX</td>\n",
       "      <td>2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tags</td>\n",
       "      <td>94730</td>\n",
       "      <td>3</td>\n",
       "      <td>Older American</td>\n",
       "      <td>54881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>consumer_consent_provided?</td>\n",
       "      <td>208151</td>\n",
       "      <td>4</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>114704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>submitted_via</td>\n",
       "      <td>670598</td>\n",
       "      <td>6</td>\n",
       "      <td>Web</td>\n",
       "      <td>446035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>date_sent_to_company</td>\n",
       "      <td>670598</td>\n",
       "      <td>1767</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>company_response_to_consumer</td>\n",
       "      <td>670598</td>\n",
       "      <td>8</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>493981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>timely_response?</td>\n",
       "      <td>670598</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>652848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>consumer_disputed?</td>\n",
       "      <td>629179</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>496466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index   count  unique  \\\n",
       "0                  date_received  670598    1818   \n",
       "1                        product  670598      12   \n",
       "2                    sub_product  472396      47   \n",
       "3                          issue  670598      95   \n",
       "4                      sub_issue  269868      68   \n",
       "5   consumer_complaint_narrative  114704  112690   \n",
       "6        company_public_response  145197      10   \n",
       "7                        company  670598    3933   \n",
       "8                          state  665293      62   \n",
       "9                       zip_code  665274   27889   \n",
       "10                          tags   94730       3   \n",
       "11    consumer_consent_provided?  208151       4   \n",
       "12                 submitted_via  670598       6   \n",
       "13          date_sent_to_company  670598    1767   \n",
       "14  company_response_to_consumer  670598       8   \n",
       "15              timely_response?  670598       2   \n",
       "16            consumer_disputed?  629179       2   \n",
       "\n",
       "                                                  top    freq  \n",
       "0                                          08/27/2015     963  \n",
       "1                                            Mortgage  210324  \n",
       "2                                      Other mortgage   81715  \n",
       "3            Loan modification,collection,foreclosure  106455  \n",
       "4                                      Account status   32633  \n",
       "5   I am filing this complaint because Experian ha...     102  \n",
       "6   Company has responded to the consumer and the ...   57364  \n",
       "7                                     Bank of America   61720  \n",
       "8                                                  CA   97640  \n",
       "9                                               300XX    2147  \n",
       "10                                     Older American   54881  \n",
       "11                                   Consent provided  114704  \n",
       "12                                                Web  446035  \n",
       "13                                         11/13/2015    1108  \n",
       "14                            Closed with explanation  493981  \n",
       "15                                                Yes  652848  \n",
       "16                                                 No  496466  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### All the varables are text - which may correspond to categories and other variables\n",
    "print (\" The number of unique values in each column is as follows\")\n",
    "### Lets do a describe with including objects\n",
    "complaint_data.describe(include = 'object').T.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  From above description we see that only 114704 rows have complaint text and as we are interested in only those row which have complaint text. We wll drop all rows where complaint narrative is na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Keep only the consumer complaints is not null\n",
    "complaint_data = complaint_data[~complaint_data['consumer_complaint_narrative'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24a8a128>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Create a distirbution of length of customers complaints. We have very left skew in length of complaints\n",
    "### Which is expected as most compalints can be written in less than 500 words\n",
    "complaint_data['consumer_complaint_narrative'].apply(len).plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep the length columns as a new column\n",
    "complaint_data['comp_length'] = complaint_data['consumer_complaint_narrative'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first craete the data processing pipeline to do cleaning on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "### Remove the stop words using spacy predefined list \n",
    "stop_words = nlp.Defaults.stop_words\n",
    "#### Create a list of puntuation to be removed\n",
    "symbols = \" \".join(string.punctuation).split(\" \") \n",
    "### As we are doing topic modelling itsa good idea to do lemmatisation - as it uses morphologial analysis\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#### Lets define the cleaning function and see how it works\n",
    "def cleanup_text(docs,logging = False):\n",
    "    texts = []\n",
    "    counter = 1\n",
    "    for doc in docs:\n",
    "        \n",
    "        if counter % 5000 == 0 :\n",
    "            print (\"Processed %d of out of %d documents\"% (counter,len(docs)))\n",
    "        counter += 1\n",
    "        \n",
    "        doc = nlp(doc,disable = ['parser','NER']) ### We are disabling parser as will nt be using it\n",
    "        \n",
    "        \n",
    "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != \"-pron-\"]\n",
    "        \n",
    "        tokens =[tok for tok in tokens if tok not in symbols]\n",
    "        tokens = [tok for tok in tokens if tok not in stop_words]\n",
    "        tokens = [tok for tok in tokens if len(tok)> 1]\n",
    "        tokens = ' '.join(tokens)\n",
    "        texts.append(tokens)\n",
    "    return (pd.Series(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000 of out of 114704 documents\n",
      "Processed 10000 of out of 114704 documents\n",
      "Processed 15000 of out of 114704 documents\n",
      "Processed 20000 of out of 114704 documents\n",
      "Processed 25000 of out of 114704 documents\n",
      "Processed 30000 of out of 114704 documents\n",
      "Processed 35000 of out of 114704 documents\n",
      "Processed 40000 of out of 114704 documents\n",
      "Processed 45000 of out of 114704 documents\n",
      "Processed 50000 of out of 114704 documents\n",
      "Processed 55000 of out of 114704 documents\n",
      "Processed 60000 of out of 114704 documents\n",
      "Processed 65000 of out of 114704 documents\n",
      "Processed 70000 of out of 114704 documents\n",
      "Processed 75000 of out of 114704 documents\n",
      "Processed 80000 of out of 114704 documents\n",
      "Processed 85000 of out of 114704 documents\n",
      "Processed 90000 of out of 114704 documents\n",
      "Processed 95000 of out of 114704 documents\n",
      "Processed 100000 of out of 114704 documents\n",
      "Processed 105000 of out of 114704 documents\n",
      "Processed 110000 of out of 114704 documents\n"
     ]
    }
   ],
   "source": [
    "complaint_data['comp_preprocessed'] = cleanup_text(complaint_data['consumer_complaint_narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data before removing NA's , (114704, 20)\n",
      "Shape of data before removing NA's , (19295, 20)\n"
     ]
    }
   ],
   "source": [
    "print (\"Shape of data before removing NA's ,\",complaint_data.shape)\n",
    "complaint_data =complaint_data[~complaint_data['comp_preprocessed'].isna()]\n",
    "print (\"Shape of data before removing NA's ,\",complaint_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57729     -pron- dispute xxxx xxxx xxxx experian occasio...\n",
       "57787     -pron- check account bb t. -pron- mortgage xxx...\n",
       "57838     -pron- attempt tax lien withdraw -pron- experi...\n",
       "57848     -pron- agree pay settlement xxxx midland credi...\n",
       "57852     xx xx xxxx -pron- wage -pron- earn -pron- job ...\n",
       "57864     company continue report -pron- credit report -...\n",
       "57865     phone convergent outsourcing xxxx -pron- debt ...\n",
       "57868     -pron- co executor -pron- father estate -pron-...\n",
       "57871     -pron- charge fee -pron- speak xxxx xxxx xxxx ...\n",
       "57872     local collection attorney sue -pron- use origi...\n",
       "57874     log xxxx xxxx xxxx 2014 -pron- state access gr...\n",
       "57882     evaluation -pron- credit report -pron- notice ...\n",
       "57884     -pron- receive phone xxxx xxxx xxxx 2015 xxxx ...\n",
       "57893     sent letter response unfortunately -pron- vict...\n",
       "57894     nationstar send statement date variance range ...\n",
       "57912     happen people use xxxx website thing happen ti...\n",
       "57921     recontrust dual tracking improper transaction ...\n",
       "57938     -pron- try arrangement catch -pron- car paymen...\n",
       "57939     premisesthe adjustable rate note subject loan ...\n",
       "57941     xxxx xxxx xxxx contact -pron- regard citibank ...\n",
       "57945     -pron- send letter -pron- regard matter send r...\n",
       "57946     macy collection department xxxx send automate ...\n",
       "57951     -pron- personal loan -pron- tower loan verify ...\n",
       "57952     ocwen loan servicing servicer -pron- loan -pro...\n",
       "57960     -pron- suffer financial hardship -pron- submit...\n",
       "57963     -pron- mother pass away year ago -pron- try ba...\n",
       "57968     -pron- dispute xxxx overcharge -pron- invoice ...\n",
       "57970     -pron- co signer loan -pron- believe borrower ...\n",
       "57978     -pron- complaint midland funding llc -pron- qu...\n",
       "57979     equifax refuse report -pron- xxxx installment ...\n",
       "                                ...                        \n",
       "112162    apply business loan today -pron- month -pron- ...\n",
       "112164    xxxx hit -pron- trans union credit report xxxx...\n",
       "112167    xxxx xxxx 2016 xxxx fraudulent application cre...\n",
       "112169    harris harris '' debt collector xxxx -pron- nu...\n",
       "112170    experian -pron- fico score continue report inc...\n",
       "112171    collection agency commonwealth financial syste...\n",
       "112175    -pron- sister -pron- mother autodialer leave l...\n",
       "112177    ditech greentree financial institution hold xx...\n",
       "112180    -pron- receive voicemail xxxx able discern -pr...\n",
       "112182    -pron- complain manager owner tower loan conce...\n",
       "112187    -pron- mortgage holder xxxx xxxx xxxx transfer...\n",
       "112860    -pron- open -pron- account santander late year...\n",
       "112979    -pron- dispute issue experian list incorrect a...\n",
       "113038    -pron- letter great lakes state -pron- owe 200...\n",
       "113110    equifax let xxxx xxxx xxxx report incorrect in...\n",
       "113457    request -pron- credit score xx xx xxxx tell -p...\n",
       "113466    progress card report -pron- owe -pron- xxxx -p...\n",
       "113609    try buy car -pron- find deb -pron- -pron- disp...\n",
       "113796    -pron- fiancee -pron- process purchase new hom...\n",
       "113985    debt xxxx xxxx check account credit card past ...\n",
       "114002    debt settle pay judgement satisifie nj court p...\n",
       "114006    way notice -pron- want provide -pron- complain...\n",
       "114027    -pron- victim identity theft submit -pron- ide...\n",
       "114028    company throw possible obstacle consumer reque...\n",
       "114043    penn credit agree remove collection -pron- xxx...\n",
       "114045    false information present computer screen use ...\n",
       "114247    -pron- trick sell house owner finance house ve...\n",
       "114309    -pron- sell personal property xxxx time time r...\n",
       "114553    -pron- try refinance -pron- mortgage work coll...\n",
       "114619    xxxx 2015 -pron- hit year hamp anniversary ent...\n",
       "Name: comp_preprocessed, Length: 19295, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaint_data['comp_preprocessed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets tranform the data using TFIDF vectoriser\n",
    "1. For learning purpose i am using only tf-idf , but inpractical it as advised to trial out count vectoriser also\n",
    "2. Also, all paarmeters in TF IDF can be treated as Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the tf-idf features form NMF\n",
      "done in 23.071s.\n"
     ]
    }
   ],
   "source": [
    "### Lets Create the piprle line for NMF models \n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF \n",
    "#####  Let extract from act the features from the dataset\n",
    "\n",
    "print (\"Extracting the tf-idf features form NMF\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.5, min_df = 5, max_features = 500, ngram_range = (1,4))\n",
    "\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(complaint_data['comp_preprocessed'])\n",
    "print (\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 26.936 \n",
      "done in 65.124 \n",
      "done in 109.590 \n",
      "done in 141.636 \n",
      "done in 203.881 \n",
      "done in 255.166 \n",
      "done in 329.132 \n"
     ]
    }
   ],
   "source": [
    "#### Now we will fit model for 10 diff values of clusters\n",
    "n_comp = [10,20,30,40,50,60,70,80,90,100,110]\n",
    "\n",
    "for comps in n_comp:\n",
    "    loss = []\n",
    "    t0 = time()\n",
    "    nmf = NMF(n_components = comps, random_state = 1, beta_loss = 'kullback-leibler',solver = 'mu',max_iter = 200,\n",
    "             alpha = 0.1, l1_ratio = 0.5).fit(tfidf)\n",
    "    loss.append(nmf.reconstruction_err_)\n",
    "    print (\"done in %0.3f \" % (time() -t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let try to create a elbow and find out the best model clusters\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Reconstruction Error - Frobenius Norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function which goes through - topic * word matrix and extract the top keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the NMF model\n",
    "#### Now we will fit model for 10 diff values of clusters\n",
    "n_comp = [10,20,30,40,50,60,70,80,90,100,110]\n",
    "\n",
    "for comps in n_comp:\n",
    "    loss1 = []\n",
    "    print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "          \"n_samples=%d and n_features=%d...\"\n",
    "          % (n_samples, n_features))\n",
    "    t0 = time()\n",
    "    lda = LatentDirichletAllocation(n_components=comps, max_iter=2,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "    lda.fit(tfidf)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
